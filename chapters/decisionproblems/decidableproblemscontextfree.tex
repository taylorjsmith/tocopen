\section{Decidable Problems for Context-Free Languages}\label{sec:decidableCFL}

\firstwords{Moving on to the class} of context-free languages, we will again consider each of the common decision problems in turn, but here we must make a decision: much like we chose to prove regular language decidability results with the deterministic finite automaton model, do we prove context-free decidability results with the pushdown automaton model or with the context-free grammar model?

If we were to go with the pushdown automaton approach, we would have the familiarity in our proofs of simulating the computation of a simpler machine on a Turing machine, exactly as we did in the previous section. On the other hand, we would need to devise some way of managing the stack of this machine as we simulate its computation, and this added complexity would make our proofs somewhat more difficult.

By contrast, going with the context-free grammar approach, we can easily simulate a derivation (which is a computation in disguise) just by manipulating the rules of the context-free grammar in an appropriate manner. Since we know that context-free grammars and pushdown automata are equivalent in terms of recognition power, we lose nothing by selecting the grammar model over the automaton model, and so we will make our lives easier and take the grammar approach in this section.

\subsection*{Membership Problem}

As before, we begin with the simplest of decision problems. If we're given an input $\langle G, w \rangle$, where $G$ is a context-free grammar and $w$ is a word over the grammar's terminal alphabet $\Sigma$, the membership problem asks whether $G$ is capable of generating the word $w$.

The na\"{\i}ve approach to determining whether $G$ generates $w$ would have us check every possible derivation using the rules of $G$. However, this isn't a good approach, since in the worst case our algorithm may need to check infinitely many derivations. In fact, if we tried this approach and $G$ actually couldn't generate $w$, then our algorithm would keep checking derivations fruitlessly and would never halt! Thus, while the na\"{\i}ve approach \emph{semidecides} the problem, it doesn't \emph{decide} the problem.

We must somehow ensure that we only check some finite number of derivations in the process of testing membership. Thinking back to our discussion of Chomsky normal form, we made one important observation that will help us greatly: recall that if a context-free grammar in Chomsky normal form generates a word $w$, then the derivation of $w$ will take $2|w| - 1$ steps. This allows us to place an upper bound on the length of the derivation and, therefore, a limit on the number of steps performed by our membership-testing algorithm!

Using this observation, our decision algorithm will first convert its given context-free grammar $G$ to Chomsky normal form and then only check candidate derivations of $w$ that take $2|w| - 1$ steps. If $w$ can indeed be generated by $G$, then its derivation will be found by the algorithm.

\begin{theorem}\label{thm:ACFGdecidable}
$\mathit{A}_{\CFG}$ is decidable.

\begin{proof}
Construct a Turing machine $\mathcal{M}_{\mathrm{ACFG}}$ that takes as input $\langle G, w \rangle$, where $G$ is a context-free grammar and $w$ is a word, and performs the following steps:
\tmalgorithm{$\mathcal{M}_{\mathrm{ACFG}}$}{
\begin{enumerate}
\item Convert $G$ to an equivalent grammar $G'$ in Chomsky normal form.
\item Check the length of $w$:
	\begin{itemize}
	\item If $|w| = 0$, then list all derivations using $G'$ that take a single step.
	\item If $|w| \geq 1$, then list all derivations using $G'$ that take $2|w| - 1$ steps.
	\end{itemize}
\item If any of these derivations generate $w$, then accept. Otherwise, reject.
\end{enumerate}
}
This Turing machine accepts its input $\langle G, w \rangle$ if and only if the context-free grammar $G$ is capable of generating the word $w$; that is, if and only if $w \in L(G)$. Likewise, the Turing machine rejects if and only if no derivation exists that allows $G$ to generate $w$; that is, if and only if $w \not\in L(G)$. Since the process of converting $G$ to Chomsky normal form as well as the process of listing all derivations of a given length are finite, the Turing machine will never become trapped in an infinite computation. Thus, $\mathcal{M}_{\mathrm{ACFG}}$ decides the membership problem for context-free grammars.
\end{proof}
\end{theorem}

Unsurprisingly, the same positive decidability result holds for the pushdown automaton model.

\begin{corollary}
$\mathit{A}_{\PDA}$ is decidable.

\begin{proof}
Given a pushdown automaton $\mathcal{P}$, we can convert it to an equivalent context-free grammar $G$ and run $\mathcal{M}_{\mathrm{ACFG}}$ from the proof of Theorem~\ref{thm:ACFGdecidable} on the input $\langle G, w \rangle$.
\end{proof}
\end{corollary}

Reviewing our proof of Theorem~\ref{thm:ACFGdecidable} may make it more evident why we chose context-free grammars as our model in this section instead of pushdown automata: with grammars, we can obtain a concrete upper bound on how much work our Turing machine has to do before producing an answer.

On the other hand, if we're given a pushdown automaton as input, then we know we can simulate the computation of this automaton on a Turing machine in a rather straightforward manner. However, there's no way for us to predict in advance whether some branch of the pushdown automaton's computation tree will go on forever without accepting. Consider, for example, the branch of the computation tree that corresponds to following these two transitions repeatedly:
\begin{center}
\begin{tikzpicture}[node distance=3cm, >=latex, every state/.style={fill=white}]
\node[draw=none] (q) {$\dots$};
\node[state, minimum size=1cm] (q0) [right=1cm of q] {$q_{i}$};
\node[state, minimum size=1cm] (q1) [right of=q0] {$q_{i+1}$};
\node[draw=none] (qr) [right=1cm of q1] {$\dots$};

\path[-latex] (q) edge [above] node {} (q0);
\path[-latex] (q0) edge [bend left, above] node {$\epsilon, \epsilon \mapsto A$} (q1);
\path[-latex] (q1) edge [bend left, below] node {$\epsilon, A \mapsto \epsilon$} (q0);
\path[-latex] (q1) edge [above] node {} (qr);
\end{tikzpicture}
\end{center}
If our Turing machine na\"{\i}vely simulates the computation of the pushdown automaton by descending into individual branches of the computation tree one-by-one, then it could fall into this infinite-length branch trap. As a consequence, we can't guarantee that our Turing machine decides whether or not the pushdown automaton accepts its input word, and so we can't establish a positive decidability result for the membership problem unless we put in the additional work to avoid infinite-length branches in the computation tree.

By comparison, doesn't our context-free grammar approach seem so much more appealing?

\subsection*{Emptiness Problem}

For the emptiness problem, we again have a na\"{\i}ve approach to check whether $L(G) = \emptyset$ for some context-free grammar $G$: for all words $w$ over the terminal alphabet $\Sigma$, verify that there exists no derivation $S \Rightarrow^{*} w$ from the start nonterminal $S$ to some sequence of terminal symbols $w$. This is, of course, not a good approach for the same reason as before: the pesky notion of infinity gets in our way. There is an infinite number of words over $\Sigma$ for which we must test membership, so if the language $L(G)$ truly were empty, an algorithm following this approach would never halt. We would just keep checking and rejecting candidate words!

Instead, we will take an opposite approach to testing the emptiness of the grammar's language. Instead of checking that no sequence of \emph{terminal} symbols is generated by the grammar, we will check, for each \emph{nonterminal} symbol, whether that individual symbol yields some sequence of previously marked terminal symbols. If this is the case, then we will mark that nonterminal symbol. Then, whenever a marked nonterminal symbol appears in a derivation, we know that some sequence of terminal symbols will appear later in the derivation, and thus the grammar's language is nonempty.

Our decision algorithm for $E_{\CFG}$ works a lot like our decision algorithm for $E_{\DFA}$, except backwards: while the algorithm for $E_{\DFA}$ marked states starting from the initial state and leading to a final state, our algorithm for $E_{\CFG}$ will mark symbols starting from the terminal symbols and returning to the start nonterminal.

\begin{theorem}\label{thm:ECFGdecidable}
$\mathit{E}_{\CFG}$ is decidable.

\begin{proof}
Construct a Turing machine $\mathcal{M}_{\mathrm{ECFG}}$ that takes as input $\langle G \rangle$, where $G$ is a context-free grammar, and performs the following steps:
\tmalgorithm{$\mathcal{M}_{\mathrm{ECFG}}$}{
\begin{enumerate}
\item Mark all terminal symbols in $G$.
\item If $G$ has a rule of the form $A \rightarrow \alpha_{1} \dots \alpha_{k}$ and each symbol $\alpha_{1}, \dots, \alpha_{k}$ has already been marked, then mark the symbol $A$. Repeat until no new symbols are marked.
\item If the start nonterminal of $G$ has not been marked, then accept. Otherwise, reject.
\end{enumerate}
}
This Turing machine accepts its input $\langle G \rangle$ if and only if there exists no derivation $S \Rightarrow^{*} w$ in the context-free grammar $G$ from the start nonterminal $S$ to some sequence of terminal symbols $w$, and the Turing machine rejects if and only if such a derivation exists in $G$. Since the number of terminal symbols to mark and the number of rules of $G$ to check are both finite, the Turing machine will never become trapped in an infinite computation. Thus, $\mathcal{M}_{\mathrm{ECFG}}$ decides the emptiness problem for context-free grammars.
\end{proof}
\end{theorem}

As we have come to expect, the same result holds for pushdown automata.

\begin{corollary}
$\mathit{E}_{\PDA}$ is decidable.
\end{corollary}